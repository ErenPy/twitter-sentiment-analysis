{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "un_labeled = pd.read_csv(\"~/Desktop/twitter-research/15-Dec/df2.csv\", lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = pd.DataFrame()\n",
    "fit_l = pd.read_csv(\"~/Desktop/fit.csv\", lineterminator='\\n', names=['Labels'], skip_blank_lines = False).reset_index()\n",
    "fit_t = pd.read_csv(\"~/Desktop/fit.txt\", lineterminator='\\n', names=['Tweets'], skip_blank_lines = False).reset_index()\n",
    "fit[\"Tweets\"] = fit_t.Tweets\n",
    "fit[\"Labels\"] = fit_l.Labels\n",
    "fit = fit.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = pd.DataFrame()\n",
    "predict_l = pd.read_csv(\"~/Desktop/predict.csv\", lineterminator='\\n', names=['Labels'], skip_blank_lines = False).reset_index()\n",
    "predict_t = pd.read_csv(\"~/Desktop/predict.txt\", lineterminator='\\n', names=['Tweets'], skip_blank_lines = False).reset_index()\n",
    "predict[\"Tweets\"] = predict_t.Tweets#predict_t.Tweets\n",
    "predict[\"Labels\"] = predict_l.Labels#predict_l.Labels\n",
    "predict = predict.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = pd.read_csv(\"Desktop/df.txt\", names = [\"Tweets\"], lineterminator='\\n', skip_blank_lines = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>üniversite hayat yasa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cezasız kal um</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anne be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yanlış 2010 facebook paylaşım kesit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hafif insan ağır gel olay ibaret</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920799</th>\n",
       "      <td>zorbalık sınır yok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920800</th>\n",
       "      <td>boykot konu gerçek babacan söyle nal toplat ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920801</th>\n",
       "      <td>müsiad liyakat yer liyakat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920802</th>\n",
       "      <td>ayıp etmiş bekle ban arkadaş göster se olduk s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920803</th>\n",
       "      <td>mart yaz gel istisna kaide boz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>920804 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Tweets\n",
       "0                                  üniversite hayat yasa \n",
       "1                                         cezasız kal um \n",
       "2                                                anne be \n",
       "3                    yanlış 2010 facebook paylaşım kesit \n",
       "4                       hafif insan ağır gel olay ibaret \n",
       "...                                                   ...\n",
       "920799                                zorbalık sınır yok \n",
       "920800  boykot konu gerçek babacan söyle nal toplat ch...\n",
       "920801                        müsiad liyakat yer liyakat \n",
       "920802  ayıp etmiş bekle ban arkadaş göster se olduk s...\n",
       "920803                    mart yaz gel istisna kaide boz \n",
       "\n",
       "[920804 rows x 1 columns]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2),\n",
    "                      token_pattern=r'\\b\\w+\\b', min_df=1)),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB()),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB()),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2),\n",
    "                      token_pattern=r'\\b\\w+\\b', min_df=1)),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                           alpha=1e-3, random_state=42,\n",
    "                                           max_iter=5, tol=None)),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                           alpha=1e-3, random_state=42,\n",
    "                                           max_iter=5, tol=None)),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbor_count = 220\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', KNeighborsClassifier(n_neighbors=neighbor_count)),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "un_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before Lemma\n",
    "text_clf.fit(fit.Tweets, fit.Labels)\n",
    "\n",
    "predicted = text_clf.predict(predict.Tweets.astype(str).tolist())\n",
    "\n",
    "#actual = predict.Labels.astype(int).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "#right = 0\n",
    "#count = 0\n",
    "predictions = []\n",
    "for p in predicted:\n",
    "    predictions.append(p)\n",
    "    #if int(actual[count]) == int(p):\n",
    "        #right += 1\n",
    "    #count += 1\n",
    "\n",
    "#print(np.mean(predicted == actual))\n",
    "#print(metrics.confusion_matrix(actual, predicted))\n",
    "#print(\"Accuracy: \" + str((float(right)/len(actual)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict['Labels'] = predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>üniversite hayat yasa</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cezasız kal um</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anne be</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yanlış 2010 facebook paylaşım kesit</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hafif insan ağır gel olay ibaret</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920799</th>\n",
       "      <td>zorbalık sınır yok</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920800</th>\n",
       "      <td>boykot konu gerçek babacan söyle nal toplat ch...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920801</th>\n",
       "      <td>müsiad liyakat yer liyakat</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920802</th>\n",
       "      <td>ayıp etmiş bekle ban arkadaş göster se olduk s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920803</th>\n",
       "      <td>mart yaz gel istisna kaide boz</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>920804 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Tweets  Labels\n",
       "0                                  üniversite hayat yasa       -1\n",
       "1                                         cezasız kal um       -1\n",
       "2                                                anne be       -1\n",
       "3                    yanlış 2010 facebook paylaşım kesit        0\n",
       "4                       hafif insan ağır gel olay ibaret       -1\n",
       "...                                                   ...     ...\n",
       "920799                                zorbalık sınır yok       -1\n",
       "920800  boykot konu gerçek babacan söyle nal toplat ch...       0\n",
       "920801                        müsiad liyakat yer liyakat       -1\n",
       "920802  ayıp etmiş bekle ban arkadaş göster se olduk s...       0\n",
       "920803                    mart yaz gel istisna kaide boz       -1\n",
       "\n",
       "[920804 rows x 2 columns]"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict.to_csv(\"new_Predicted_2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"nw.csv\", lineterminator='\\n', skip_blank_lines = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
